{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c20982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d50c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accidents.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1ec509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1370d296e30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da41986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a7f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8119c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y) #one hot process done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7cf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2555ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21006e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af20a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d94402",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb02ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 22s 4s/step\n",
      "3/3 [==============================] - 8s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5a6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57001716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586cff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36420f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e00a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 5s 752ms/step - loss: 0.6460 - accuracy: 0.6452 - val_loss: 0.8330 - val_accuracy: 0.6716\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 2s 473ms/step - loss: 0.5044 - accuracy: 0.7613 - val_loss: 0.8364 - val_accuracy: 0.6716\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 2s 461ms/step - loss: 0.3010 - accuracy: 0.8323 - val_loss: 0.9568 - val_accuracy: 0.6418\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 2s 459ms/step - loss: 0.1457 - accuracy: 0.9484 - val_loss: 0.9338 - val_accuracy: 0.7313\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 2s 458ms/step - loss: 0.1307 - accuracy: 0.9613 - val_loss: 0.8666 - val_accuracy: 0.7164\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 2s 440ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.7164\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.0550 - accuracy: 0.9935 - val_loss: 0.8447 - val_accuracy: 0.7313\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 2s 450ms/step - loss: 0.0331 - accuracy: 0.9935 - val_loss: 0.8225 - val_accuracy: 0.7761\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 2s 464ms/step - loss: 0.0304 - accuracy: 0.9935 - val_loss: 0.7987 - val_accuracy: 0.7910\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7761\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 2s 469ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.8145 - val_accuracy: 0.7612\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 2s 466ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.7761\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 2s 504ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.7761\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.7761\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 2s 433ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8317 - val_accuracy: 0.7761\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 2s 422ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.7761\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.7761\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 2s 449ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.7761\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 2s 433ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8456 - val_accuracy: 0.7761\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.7761\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 0.7761\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 2s 446ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.7761\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 2s 485ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.8527 - val_accuracy: 0.7761\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 2s 478ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.7761\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 2s 473ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.7761\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 2s 465ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.7761\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 2s 467ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8614 - val_accuracy: 0.7761\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 2s 445ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7761\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 2s 454ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8675 - val_accuracy: 0.7761\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 2s 486ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8688 - val_accuracy: 0.7761\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 3s 527ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8719 - val_accuracy: 0.7761\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 3s 522ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.7761\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 3s 593ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.7761\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 3s 531ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7761\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 3s 549ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.7761\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 2s 501ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.7761\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 3s 535ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8824 - val_accuracy: 0.7761\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 2s 472ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.7761\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8855 - val_accuracy: 0.7761\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8872 - val_accuracy: 0.7761\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 2s 463ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.7910\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 2s 446ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.7910\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.7910\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7761\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 2s 424ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.7761\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 2s 423ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.7761\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 2s 420ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8999 - val_accuracy: 0.7761\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 2s 420ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.7910\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.7910\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 2s 415ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9053 - val_accuracy: 0.7910\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 2s 421ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.7910\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9082 - val_accuracy: 0.7910\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 2s 413ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.7910\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 2s 426ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9119 - val_accuracy: 0.7910\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 2s 456ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.7910\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9157 - val_accuracy: 0.7910\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9162 - val_accuracy: 0.7910\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 2s 458ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.7910\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 2s 464ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.8060\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.8060\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 2s 462ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.8060\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 2s 465ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.8209\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 2s 479ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9249 - val_accuracy: 0.8209\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 2s 460ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 2s 462ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9267 - val_accuracy: 0.8060\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 2s 460ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.8209\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 2s 473ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 2s 457ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 2s 460ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 2s 455ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9341 - val_accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 2s 488ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9361 - val_accuracy: 0.8209\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 2s 494ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9372 - val_accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 2s 466ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.8209\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 2s 429ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9402 - val_accuracy: 0.8209\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 2s 424ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9422 - val_accuracy: 0.8209\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9428 - val_accuracy: 0.8209\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.8209\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 2s 425ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 2s 439ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.8209\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9507 - val_accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 2s 424ms/step - loss: 9.9789e-04 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8209\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 9.7815e-04 - accuracy: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.8209\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 9.5795e-04 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.8209\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 9.4062e-04 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 2s 436ms/step - loss: 9.2380e-04 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.8209\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 9.0470e-04 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.8209\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 2s 438ms/step - loss: 8.8985e-04 - accuracy: 1.0000 - val_loss: 0.9599 - val_accuracy: 0.8209\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 2s 421ms/step - loss: 8.7245e-04 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.8209\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 2s 439ms/step - loss: 8.5608e-04 - accuracy: 1.0000 - val_loss: 0.9620 - val_accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 2s 455ms/step - loss: 8.4132e-04 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.8209\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 2s 433ms/step - loss: 8.2673e-04 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.8209\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 8.1231e-04 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.8209\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 7.9851e-04 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.8209\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 7.8348e-04 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.8209\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 2s 429ms/step - loss: 7.6963e-04 - accuracy: 1.0000 - val_loss: 0.9678 - val_accuracy: 0.8209\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 2s 420ms/step - loss: 7.5649e-04 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 2s 444ms/step - loss: 7.4391e-04 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "494768fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM\\Accident Detection-Video.ipynb Cell 19\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/Accident%20Detection-Video.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mmodel.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8d52fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf0f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9047ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f32558f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff1260b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9f69282",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "721c02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb5b165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.1417576e-06 9.9999285e-01]\n",
      " [4.7724321e-04 9.9952281e-01]\n",
      " [6.1644884e-03 9.9383551e-01]\n",
      " [2.4348004e-03 9.9756527e-01]\n",
      " [5.2715712e-03 9.9472851e-01]\n",
      " [6.1549288e-01 3.8450715e-01]\n",
      " [8.5160816e-01 1.4839186e-01]\n",
      " [6.4796567e-01 3.5203433e-01]\n",
      " [8.9549172e-01 1.0450832e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f040ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\n# Train the model and store the history\\nhistory = model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))\\n\\n# Plot the training and validation loss over time\\nplt.plot(history.history['loss'])\\nplt.plot(history.history['val_loss'])\\nplt.title('Model Loss')\\nplt.ylabel('Loss')\\nplt.xlabel('Epoch')\\nplt.legend(['Train', 'Validation'], loc='upper right')\\nplt.show()\\n\\n# Plot the training and validation accuracy over time\\nplt.plot(history.history['accuracy'])\\nplt.plot(history.history['val_accuracy'])\\nplt.title('Model Accuracy')\\nplt.ylabel('Accuracy')\\nplt.xlabel('Epoch')\\nplt.legend(['Train', 'Validation'], loc='lower right')\\n\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the history\n",
    "history = model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Plot the training and validation loss over time\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy over time\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c895bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.show()\\nplt.show()'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.show()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e66b91f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status code Unknown from http://ipinfo.io/json: ERROR - HTTPConnectionPool(host='ipinfo.io', port=80): Max retries exceeded with url: /json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001371C30EB90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "g = geocoder.ip('me')\n",
    "locname = geoLoc.reverse(g.latlng)\n",
    "account_sid = 'ACde7a1cc7e1e9cdc46c1d95bef1b3becc'\n",
    "auth_token = '7c9f1c6e4ba1169a0cb6b6ee669681a1'\n",
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture('Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+locname.address,\n",
    "                 from_= '+15855132640',\n",
    "                 to= '+917510764209' )\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a76e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://10.82.234.81:8080/video'\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(url)\n",
    "'''cap = cv2.VideoCapture('Accident-1.mp4')'''\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+locname.address,\n",
    "                 from_= '+15855132640',\n",
    "                 to= '+917510764209' )\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a6a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaa0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab12e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
