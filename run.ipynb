{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "[[4.2383704e-06 9.9999571e-01]\n",
      " [2.3532781e-04 9.9976462e-01]\n",
      " [3.4100844e-03 9.9658990e-01]\n",
      " [1.6617014e-03 9.9833822e-01]\n",
      " [4.9819010e-03 9.9501812e-01]\n",
      " [6.7037177e-01 3.2962826e-01]\n",
      " [8.7104225e-01 1.2895779e-01]\n",
      " [6.9461960e-01 3.0538046e-01]\n",
      " [9.1723567e-01 8.2764402e-02]]\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n",
      "Accident\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM\\run.ipynb Cell 4\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/run.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m client \u001b[39m=\u001b[39m Client(account_sid, auth_token)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/run.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/run.ipynb#W2sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstreamlit\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mst\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/run.ipynb#W2sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/run.ipynb#W2sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Import the necessary libraries for object detection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Desktop/ACCIDENT-DETECTION-WITH-A-REPORTING-SYSTEM/run.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# e.g., TensorFlow or PyTorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import streamlit as st\n",
    "import geocoder\n",
    "from geopy.geocoders import Nominatim\n",
    "from twilio.rest import Client\n",
    "\n",
    "def main():\n",
    "    st.title(\"Accident Detection App\")\n",
    "    st.write(\"Upload a video file to detect accidents and send alerts.\")\n",
    "\n",
    "    # File uploader\n",
    "    video_file = st.file_uploader(\"Upload a video\", type=[\"mp4\", \"avi\"])\n",
    "\n",
    "    if video_file is not None:\n",
    "        # Initialize geocoder\n",
    "        geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "        g = geocoder.ip('me')\n",
    "        locname = geoLoc.reverse(g.latlng)\n",
    "\n",
    "        # Initialize Twilio client\n",
    "        account_sid = 'ACde7a1cc7e1e9cdc46c1d95bef1b3becc'\n",
    "        auth_token = '7c9f1c6e4ba1169a0cb6b6ee669681a1'\n",
    "        client = Client(account_sid, auth_token)\n",
    "\n",
    "        # Load the video\n",
    "        cap = cv2.VideoCapture(video_file.name)\n",
    "        i = 0\n",
    "        flag = 0\n",
    "\n",
    "        # Process frames\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if predictions[int(i/15) % 9][0] < predictions[int(i/15) % 9][1]:\n",
    "                predict = \"No Accident\"\n",
    "            else:\n",
    "                predict = \"Accident\"\n",
    "                flag = 1\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame,\n",
    "                        predict,\n",
    "                        (50, 50),\n",
    "                        font, 1,\n",
    "                        (0, 255, 255),\n",
    "                        3,\n",
    "                        cv2.LINE_4)\n",
    "\n",
    "            st.image(frame, channels=\"BGR\")\n",
    "\n",
    "            i += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Send alert if an accident is detected\n",
    "        if flag == 1:\n",
    "            client.messages.create(\n",
    "                body=\"Accident detected in \" + locname.address,\n",
    "                from_='+15855132640',\n",
    "                to='+917510764209')\n",
    "\n",
    "        # Release the video capture object\n",
    "        cap.release()\n",
    "        # Close all windows\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''cap = cv2.VideoCapture('Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+locname.address,\n",
    "                 from_= '+15855132640',\n",
    "                 to= '+917510764209' )\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
